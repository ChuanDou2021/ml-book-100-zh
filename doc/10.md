# 其它形式的学习

## 10.1 度量学习（Metric Learning)

我曾提到过衡量两个特征向量之间相似性（或差异）最常用的度量是欧氏距离和余弦相似性。这种度量选择似乎是符合逻辑，但实际上是随意的，就像在线性回归中选择平方误差一样。事实上，一个指标可以比另一个指标性能更好，取决于特定的数据集。也就是说，没有一种指标是永远完美的。

您可以创建更适合您的数据集的指标。然后可以将您的度量标准集成到任何需要度量标准的学习算法中，例如 k-means 或 kNN。您如何在不尝试所有可能性的情况下知道哪个方程式是一个好的度量标准？您可以用数据训练您的度量标准。

记住两个向量 x 和 x` 间的欧氏距离：

$$
d\left(\mathbf{x}, \mathbf{x}^{\prime}\right) \stackrel{\mathrm{def}}{=} \sqrt{\left(\mathbf{x}-\mathbf{x}^{\prime}\right)^{2}}=\sqrt{\left(\mathbf{x}-\mathbf{x}^{\prime}\right)\left(\mathbf{x}-\mathbf{x}^{\prime}\right)}
$$

我们可以稍微修改此指标以使其可参数化，然后从数据中学习这些参数。
请考虑以下修改:

$$ d_{\mathbf{A}}\left(\mathbf{x},\mathbf{x}^{\prime}\right)=\left\|\mathbf{x}-\mathbf{x}^{\prime}\right\| \mathbf{A} \stackrel{\mathrm{def}}{=} \sqrt{\left(\mathbf{x}-\mathbf{x}^{\prime}\right)^{\top} \mathbf{A}\left(\mathbf{x}-\mathbf{x}^{\prime}\right)} $$

其中 A 是 D× D 矩阵。假设 D = 3.如果我们让 A 为单位矩阵，

$$
\mathbf{A} \stackrel{\operatorname{def}}{=}\left[\begin{array}{lll}{1} & {0} & {0} \\ {0} & {1} & {0} \\ {0} & {0} & {1}\end{array}\right]
$$

则 dA 为欧几里德距离。如果我们有一个通用的对角矩阵，像这样，

$$
\mathbf{A} \stackrel{\operatorname{def}}{=}\left[\begin{array}{lll}{2} & {0} & {0} \\ {0} & {8} & {0} \\ {0} & {0} & {1}\end{array}\right]
$$

那么不同的维度在度量标准中具有不同的重要性。（在上面的例子中，第二个维度是度量计算中最重要的。）更一般地说，为了表示一个度量，两个变量的函数必须满足三个条件:

$$
\begin{array}{ll}{\text { 1. } d\left(\mathbf{x}, \mathbf{x}^{\prime}\right) \geq 0} & {\text { nonnegativity }} \\ {\text { 2. } d\left(\mathbf{x}, \mathbf{x}^{\prime}\right) \leq d\left(\mathbf{x}, \mathbf{x}^{\prime}\right)+d\left(\mathbf{x}^{\prime}, \mathbf{z}\right)} & {\text { triangle inequality }} \\ {\text { 3. } d\left(\mathbf{x}, \mathbf{x}^{\prime}\right)=d\left(\mathbf{x}^{\prime}, \mathbf{x}\right)} & {\text { symmetry }}\end{array}
$$

为了满足前两个条件，矩阵必须是半正定的。你可以看到一个半正定矩阵作为非负实数对矩阵的概念的推广。任何半正定矩阵 M 满足：

$$
\mathbf{z}^{\top} \mathbf{M z} \geq 0
$$

上述性质遵循半正定矩阵的定义。可以在本书的配套网站上找到半正定矩阵满足第二个条件证明。
为了满足第三个条件，我们可以简单地计算  $\left(d\left(\mathbf{x}, \mathbf{x}^{\prime}\right)+d\left(\mathbf{x}^{\prime}, \mathbf{x}\right)\right) / 2$

假设我们有一个未标注数据集 $\mathcal{X}=\left\{\mathbf{x}_{i}\right\}_{i=1}^{N}$。为了构建我们的度量学习问题的训练数据，我们手动创建两组。第一个数据集 S 包含这样的样本 $\left(\mathbf{x}_{i}, \mathbf{x}_{k}\right)$ ，其中 $x_{i}$ 和 $x_{k}$ 相似（从我们的主观角度来看）。第二个数据集 D 包含样本（xi，xk），其中 $x_{i}$ 和 $x_{k}$ 不相似。

为了从数据中训练参数矩阵 A，我们希望找到一个半正定矩阵 A 来解决以下优化问题：

$$
\min _{\mathbf{A}} \sum_{\left(\mathbf{x}_{i}, \mathbf{x}_{k}\right) \in \mathcal{S}}\left\|\mathbf{x}-\mathbf{x}^{\prime}\right\|_{\mathbf{A}}^{2} \text { such that } \sum_{\left(\mathbf{x}_{i}, \mathbf{x}_{k}\right) \in \mathcal{D}}\left\|\mathbf{x}-\mathbf{x}^{\prime}\right\| \mathbf{A} \geq c
$$

c 为正常数（可以是任何数）。

这种优化问题的解决方案是通过梯度下降和修改来确定的，确保找到的矩阵A是半正定的。本书未提及具体的算法描述，以供进一步阅读。您应该知道还有许多其他方法可以学习度量，包括非线性和基于核的方法。但是，本书中介绍的方法可以为大多数实际问题提供良好的结果。

![10-1](https://github.com/apachecn/ml-book-100-zh/blob/master/doc/img/10-1.png)

## 10.2 排序学习（Learning to Rank)

排序学习是一个有监督的学习问题。其中，使用排序学习的一个常见问题是搜索引擎为查询返回的搜索结果的优化。在搜索结果排名优化中，N 个样本的训练集中一个带标签的样本 $\mathcal{X}_{i}$ 是关于文档大小 $r_{i}$ 的排序集合（标签是文档的排名）。特征向量表示集合中的每个文档。学习的目标是确定排序函数，其输出的值可用于对文档进行排名。对于每个训练样本，一个理想的函数的输出应该根据给出的标签包含相同排名的文档。

 每个样本 $\mathcal{X}_{i}$， i = 1，...，N， 是一个特征向量的标签：$\mathcal{X}_{i}=\left\{\left(\mathbf{x}_{i, j}, 3 i, j\right)\right\}_{j=1}^{r} .$  特征向量 $\mathbf{x}_{i, j}$ 代表着文档  $j=1, \ldots, r_{i}$ 。比如， $\mathbf{x}_{i, j}^{(1)}$ 可以表示文本的近期情况， $\mathbf{x}_{i, j}^{(2)}$ 将反映是否可以在文档标题中找到查询的单词， $\mathbf{x}_{i, j}^{(1)}$ 代表着文档的大小，等等。而标签 $y_{i, j}$ 代表着排名 $\left(1,2, \ldots, r_{i}\right)$ 或分数。例如，分数越低，文档应该排名越高。

 解决这种学习问题有三种主要方法：单文档方法（Pointwise），文档对方法（Pairwise），文档列表方法（Listwise）。

 单文档方法将每个样本转化为多个样本：每个文档对应一个样本。学习问题是标准的监督学习问题，无论是线性回归还是逻辑回归。单文档方法中的每个样本 $(\mathbf{x}, y)$ ，X 是一些文档的特征向量，y 是初始分数（如果 $y_{i, j}$ 是分数）或从排名中获得的合成分数（排名越高，合成分数越低）。在这种情况下可以使用任何监督学习算法。解决方案通常是不完美的。原则上，这是因为每个文档被孤立地考虑，而原始排名（由原始训练集的标签 $y_{i, j}$ 给出）会优化其在整个文档集的位置。例如，如果我们已经在某些文档集合中给予某个维基百科页面高排名，我们就不会对同一查询的另一个维基百科页面给出高排名。

文档对方法中存在的问题也是将文档孤立地考虑，然而，在这种情况下，每次会考虑一对文档。给定一对文档 $\left(\mathrm{x}_{i}, \mathrm{x}_{k}\right)$ ，我们想要建立一个模型 f，将给定 $\left(\mathrm{x}_{i}, \mathrm{x}_{k}\right)$ 作为输入，如果 $\mathrm{x}_{i}$ 要比 $\mathrm{x}_{k}$ 排名更高,则输出接近1的值。否则，f 输出一个接近0的值。在测试时，给定一个模型，通过聚合 X 中所有文档对的预测获得未标记的样本 X 的最终排名。这种方法比单文档方法更好，但仍远非完美。

最先进的等级学习算法，例如LambdaMART，实现了文档列表方法。在列表方法中，我们尝试直接在一些反映出排名质量的度量上优化模型。评估搜索结果排名有各种指标，包括精确度和召回率。将精确度和召回率相结合的一种常用度量称为平均精度（MAP）。

要定义 MAP，让我们让评委（谷歌称那些人是 rankers ）检查查询的搜索结果集合，并为每个搜索结果分配相关性标签。标签可以是二进制的（1 表示“相关”，0 表示“不相关”）或某种尺度，例如 1 到 5：值越高，文档与搜索查询的相关性越高。让我们的评委为 100 个查询的集合构建相关标签。现在，让我们测试一下这个系列的排名模型。我们的模型对某些查询的精度由下式给出：

$$
\text { precision }=\frac{ |\{\text { relevant documents }\} \cap\{\text { retrieved documents }\} |}{ |\{\text { retrieved documents }\} |}
$$

这里的 |·| 代表数量。

平均精度度量标准 AveP 定义为搜索引擎为查询 q 返回的排序文档集合：

$$
\operatorname{AveP}(q)=\frac{\sum_{k=1}^{n}(P(k) \times \operatorname{rel}(k))}{ |\{\text { relevant documents }\} |}
$$

其中 n 是检索到的文档的数量。

$P(k)$ 表示由我们的查询排名模型返回的前 k 个搜索结果计算的精度，如果排名 k 的是相关文档（根据评判），则 $rel(k)$ 是等于1的指标函数，否则，函数值为零。最后，给出大小为 Q 的搜索查询集合的 MAP，

$$
\mathrm{MAP}=\frac{\sum_{q=1}^{Q} \operatorname{AveP}(\mathrm{q})}{Q}
$$

现在我们回到 LambdaMART。该算法实现了文档对方法，并使用梯度增强来训练排序函数 $h(k)$。预测文档 $\mathbf{x}_{i}$ 是否具有比文档 $\mathbf{x}_{k}$ 更高的等级（对于相同的搜索查询）的二进制模型 $f\left(\mathbf{x}_{i}, \mathbf{x}_{k}\right)$ 由具有超参数 α 的 sigmoid 函数给，

$$
f\left(\mathbf{x}_{i}, \mathbf{x}_{k}\right) \stackrel{\mathrm{def}}{=} \frac{1}{1+\exp \left(\left(h\left(\mathbf{x}_{\mathbf{i}}\right)-h\left(\mathbf{x}_{\mathbf{k}}\right)\right) \alpha\right.}
$$

 同样，与许多预测概率的模型一样，使用模型 f 对代价函数进行交叉熵计算。在梯度提升中，我们通过尝试最小化 cost 来组合多个回归树来构建函数 h。请记住，在梯度提升中，我们向模型添加树以减少当前模型对训练数据的误差。对于分类问题，我们计算了代价函数的导数，用这些导数代替训练样例的实际标签。LambdaMART 的工作方式类似，只有一个例外。它使用梯度和取决于度量的另一个因子（例如MAP）的组合来替换实际梯度。该因子通过增加或减少原始梯度来修改原始梯度，从而提高度量值。

 这是一个非常明智的想法，并不是很多监督学习算法可以直接提升他们的优化度量( matric )。优化度量是我们真正想要的，但我们在典型监督学习算法中所做的是优化代价 ( cost ) 而不是度量(matric)。通常，在监督学习中，一旦我们找到优化代价函数的模型，我们就会尝试调整超参数以提高度量的值。而 LambdaMART 直接优化度量标准

 剩下的问题是我们如何基于模型 f 的预测来构建排序的结果列表，模型 f 预测其第一个输入是否必须高于第二个输入。它通常是计算上难以解决的问题，并且存在多种能够将文档对比较转换为排序列表的工具。最直接的方法是使用现有的排序算法。

排序算法按递增或递减顺序对数字集合进行排序。（最简单的排序算法称为冒泡排序，工程学院中通常会教授它。）通常，排序算法迭代地比较集合中的一对数字，并根据比较结果更改列表中的位置。如果我们将函数 f 插入到排序算法中以执行此比较，则排序算法将对文档而不是数字进行排序。

![10-2](https://github.com/apachecn/ml-book-100-zh/blob/master/doc/img/10-2.png)

## 10.3 推荐学习（Learning to Recommend）

推荐学习是一种构建推荐系统的方法。通常，我们有一个消费某些内容的用户。我们有消费历史，我们希望向用户推荐用户想要的新内容。它可能是 Netflix 上的一部电影或亚马逊上的一本书。

传统上，有两种方法用于提供推荐：基于内容的过滤（content-based ﬁltering）和协作过滤（collaborative ﬁltering）。

![图 1：稀疏特征向量 x 及其各自标签 y 的示例](https://github.com/apachecn/ml-book-100-zh/blob/master/doc/img/10-3-1.png)

![10-3](https://github.com/apachecn/ml-book-100-zh/blob/master/doc/img/10-3.png)

## 10.4 自监督学习：词嵌入 （Word Embeddings）

我们已经在第7章讨论过 Word Embeddings。回想一下，词嵌入向量是单词的特征向量。它们具有一种特性：相似单词具有相似单词向量。您可能想问的问题是这些嵌入字来自何处。答案是：从数据中学习它们。

学习 Word Embeddings 有很多算法。在这里，我们只详细考虑其中一个：word2vec的一个特定版本叫做skip-gram，在实践中效果很好。可以在线下载多种语言的预训练 word2vec 嵌入模型。

在单词嵌入学习中，我们的目标是构建一个模型，我们可以使用该模型将单词的独热码（one-hot）转换为词嵌入。假如我们的字典包含 10000 个单词。每个单词的一个独热码向量是一个 10000 维向量的全零向量，除了一个包含 1 的维度。不同的单词在不同的维度上为 1。

考虑一句话：“I almost ﬁnished reading the book on machine learning.” 现在，考虑一下我们删除了一些单词的相同句子，比如 “book.”我们的句子变成：“I almost ﬁnished reading the·on machine learning.” 现在让我们只保留 “·”之前三个单词和在它之后的三个词：“ﬁnished reading the·on machine learning.”看着这个七字窗口，如果我要求你猜猜 “·”代表什么，你可能会说：“book,” “article,” 或者“paper.”这就是上下文单词如何让你预测它们所包围的单词。这也是机器如何发现“book,” “article,” 或者“paper.”这几个词的含义相似：因为它们在多个文本中共享相似的语境。



![10-4](https://github.com/apachecn/ml-book-100-zh/blob/master/doc/img/10-4.png)

![图 2：窗口大小为 5 的 skip-gram 模型和 300 个单元的嵌入层。](https://github.com/apachecn/ml-book-100-zh/blob/master/doc/img/10-4-1.png)
